{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ho-yu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils import MyUtils\n",
    "\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "import yaml\n",
    "import sqlite3\n",
    "\n",
    "if (sys.modules.get('src.logistic_regression') is not None): \n",
    "    del sys.modules['src.logistic_regression']\n",
    "import src.logistic_regression \n",
    "\n",
    "if (sys.modules.get('src.people_generator') is not None): \n",
    "    del sys.modules['src.people_generator']\n",
    "import src.people_generator\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(parent_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 rows of data and saved to 'bsg_people_data.csv'\n",
      "   id   first_name  last_name salutation call_sign         dob  weight_lbs  \\\n",
      "0   1  Christopher      Greer        Mr.            3677-04-22         123   \n",
      "1   2         John     Harris        Ms.            3662-11-11         115   \n",
      "2   3       Glenda     Wright        Mr.            3674-05-18         123   \n",
      "3   4       Jeanne   Trujillo        Mr.            3662-10-08         176   \n",
      "4   5       Audrey     Hunter        Dr.            3712-04-20         108   \n",
      "5   6       Gerald       Dunn        Mr.            3712-02-06         130   \n",
      "6   7      Stephen      Allen        Sir            3679-01-03         190   \n",
      "7   8       Joshua  Rodriguez        Mr.            3739-05-29         114   \n",
      "8   9        Brian   Martinez        Dr.            3667-12-20         248   \n",
      "9  10         Ruth    Hensley        Sir            3689-12-25         138   \n",
      "\n",
      "   height_m gender  dna_mutations_n home_colony_id  is_cylon  \n",
      "0      1.58      F           140136             13        -1  \n",
      "1      1.62      F           628871                       -1  \n",
      "2      1.69      M           227274              8        -1  \n",
      "3      1.71      M           387437                       -1  \n",
      "4      1.84      M           266538             12        -1  \n",
      "5      1.52      F           475191                       -1  \n",
      "6      1.53      F           635813                       -1  \n",
      "7      1.88      M               93             13         1  \n",
      "8      1.85      M           287141             13        -1  \n",
      "9      1.64      F           325604                       -1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "src.people_generator.generate_people_data(n = 20, percent_cylon = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory set to: /home/ho-yu/bsg\n",
      "dir: /home/ho-yu/bsg\n",
      "Current working directory set to: /home/ho-yu/bsg\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory set to:\", os.getcwd())\n",
    "\n",
    "# Read the config.yaml file\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "if os.path.exists('../config.yaml'):\n",
    "    with open('../config.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "dir = config['fileio']['working_directory2']\n",
    "\n",
    "print(\"dir: \" + dir)\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir(dir)\n",
    "print(\"Current working directory set to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/16 19:57:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/02/16 19:57:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"appName\").setMaster(\"local\")\n",
    "\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(dir + \"/db/simple.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+---+---------------+--------+\n",
      "|weight_lbs|height_m|gender|age|dna_mutations_n|is_cylon|\n",
      "+----------+--------+------+---+---------------+--------+\n",
      "|       155|    1.78|     0| 30|           1556|      -1|\n",
      "|       200|    1.74|     0| 60|        5454544|      -1|\n",
      "|       120|     1.6|     1| 24|          25444|      -1|\n",
      "|       160|     1.7|     0| 44|           3566|      -1|\n",
      "|       115|    1.55|     1| 55|      534354354|      -1|\n",
      "|       155|     1.7|     0| 45|            150|       1|\n",
      "|       116|    1.56|     1| 24|            188|       1|\n",
      "|       116|    1.56|     1| 24|             90|       1|\n",
      "|       170|     1.7|     0| 69|        7756664|      -1|\n",
      "|       160|     1.8|     0| 39|             35|       1|\n",
      "|       158|    1.75|     0| 32|           4415|      -1|\n",
      "|       185|    1.85|     0| 39|          11321|      -1|\n",
      "|       121|    1.59|     1| 35|          44556|      -1|\n",
      "|       150|    1.68|     0| 34|           7548|      -1|\n",
      "|       110|    1.55|     1| 22|            566|      -1|\n",
      "|       166|     1.8|     0| 35|           5785|      -1|\n",
      "|       180|    1.77|     0| 24|            445|      -1|\n",
      "+----------+--------+------+---+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bsg_cylons_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"model_number\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "\n",
    "bsg_people = spark.read.csv(dir + \"/csv/people.csv\", header=True, inferSchema=True) \\\n",
    "    .withColumnRenamed(\"id\", \"person_id\")\n",
    "\n",
    "bsg_cylons = spark.read.csv(dir + \"/csv/cylons.csv\", header=True, schema = bsg_cylons_schema) \\\n",
    "    .withColumnRenamed(\"id\", \"cylon_id\") \\\n",
    "    .withColumnRenamed(\"model_number\", \"cylons_model_number\")\n",
    "\n",
    "bsg_cylons_people = spark.read.csv(dir + \"/csv/cylons_people.csv\", header=True) \\\n",
    "    .withColumnRenamed(\"person_id\", \"cylons_people_person_id\") \\\n",
    "    .withColumnRenamed(\"model_number\", \"cylons_people_model_number\")\n",
    "\n",
    "\n",
    "bsg_data_people_cylons = bsg_people \\\n",
    "    .join(bsg_cylons_people, bsg_people.person_id == bsg_cylons_people.cylons_people_person_id, 'left') \\\n",
    "    # .join(bsg_cylons, bsg_cylons_people.cylons_people_model_number == bsg_cylons.cylons_model_number) \\\n",
    "\n",
    "\n",
    "current_year = 3760\n",
    "current_month = 4\n",
    "current_day = 12\n",
    "current_date = f\"{current_year}-{current_month:02d}-{current_day:02d}\"\n",
    "\n",
    "query1 = f\"\"\"\n",
    "    SELECT \n",
    "        weight_lbs, \n",
    "        height_m,\n",
    "        CASE \n",
    "            WHEN gender = 'M' THEN 0 \n",
    "            WHEN gender = 'F' THEN 1 \n",
    "        END AS gender,\n",
    "        YEAR(DATE('{current_date}')) - YEAR(dob) - \n",
    "            (CASE \n",
    "                WHEN MONTH(DATE('{current_date}')) < MONTH(dob) \n",
    "                        OR (MONTH(DATE('{current_date}')) = MONTH(dob) AND DAY(DATE('{current_date}')) < DAY(dob)) \n",
    "                THEN 1 ELSE 0 \n",
    "                END) AS age,\n",
    "            dna_mutations_n,    \n",
    "        CASE \n",
    "            WHEN cylons_people_model_number IS NULL THEN -1 \n",
    "            ELSE 1 \n",
    "        END AS is_cylon\n",
    "           \n",
    "    FROM bsg_data_people_cylons \n",
    "    LIMIT 100\n",
    "\"\"\"\n",
    "query2 = \"SELECT * FROM bsg_data_people_cylons LIMIT 100\"\n",
    "\n",
    "# bsg_data_people_cylons.createOrReplaceTempView(\"bsg_data_people_cylons\")\n",
    "# bsg_data_people_cylons = spark.sql(query2)\n",
    "# print(\"bsg_data_people_cylons\")\n",
    "# bsg_data_people_cylons.show()\n",
    "\n",
    "bsg_data_people_cylons.createOrReplaceTempView(\"bsg_data_people_cylons\")\n",
    "bsg_data_people_cylons = spark.sql(query1)\n",
    "# print(\"bsg_data_people_cylons\")\n",
    "# bsg_data_people_cylons.show()\n",
    "\n",
    "bsg_data_people_cylons.createOrReplaceTempView(\"bsg_data\")\n",
    "bsg_data = spark.sql(\"SELECT * FROM bsg_data\")\n",
    "bsg_data.show()\n",
    "\n",
    "# print(\"bsg_people\")\n",
    "# bsg_people.show()\n",
    "\n",
    "# print(\"bsg_cylons\")\n",
    "# bsg_cylons.show()\n",
    "\n",
    "# print(\"bsg_cylons_people\")\n",
    "# bsg_cylons_people.show()\n",
    "\n",
    "# print(\"bsg_data_people_cylons\")\n",
    "# bsg_data_people_cylons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17, 3)\n",
      "y_train shape: (17, 1)\n",
      "   gender  age  dna_mutations_n\n",
      "0       0   30             1556\n",
      "1       0   60          5454544\n",
      "2       1   24            25444\n",
      "3       0   44             3566\n",
      "4       1   55        534354354\n",
      "   is_cylon\n",
      "0        -1\n",
      "1        -1\n",
      "2        -1\n",
      "3        -1\n",
      "4        -1\n"
     ]
    }
   ],
   "source": [
    "df_pandas = bsg_data.toPandas()\n",
    "\n",
    "features =['weight_lbs', 'height_m', 'gender', 'age', 'dna_mutations_n']\n",
    "features = [\"gender\", \"age\", \"dna_mutations_n\"]\n",
    "\n",
    "X_train = df_pandas[features]\n",
    "y_train = df_pandas[['is_cylon']]\n",
    "\n",
    "X_train.to_csv(\"./data/X_train.csv\", header=False, index=False)  # No header, no index\n",
    "y_train.to_csv(\"./data/y_train.csv\", header=False, index=False)\n",
    "\n",
    "# X_train.to_csv(\"./data/X_test.csv\", header=False, index=False)  # No header, no index\n",
    "# y_train.to_csv(\"./data/y_test.csv\", header=False, index=False)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(X_train.head())  # Preview features\n",
    "print(y_train.head())  # Preview target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+---+---------------+--------+\n",
      "|weight_lbs|height_m|gender|age|dna_mutations_n|is_cylon|\n",
      "+----------+--------+------+---+---------------+--------+\n",
      "|       123|    1.58|     1| 82|         140136|      -1|\n",
      "|       115|    1.62|     1| 97|         628871|      -1|\n",
      "|       123|    1.69|     0| 85|         227274|      -1|\n",
      "|       176|    1.71|     0| 97|         387437|      -1|\n",
      "|       108|    1.84|     0| 47|         266538|      -1|\n",
      "|       130|    1.52|     1| 48|         475191|      -1|\n",
      "|       190|    1.53|     1| 81|         635813|      -1|\n",
      "|       114|    1.88|     0| 20|             93|       1|\n",
      "|       248|    1.85|     0| 92|         287141|      -1|\n",
      "|       138|    1.64|     1| 70|         325604|      -1|\n",
      "|       220|    1.53|     0| 10|            929|      -1|\n",
      "|       169|    1.89|     0| 53|         267049|      -1|\n",
      "|       196|    1.63|     0| 46|         504640|      -1|\n",
      "|       246|    1.59|     1| 21|            874|      -1|\n",
      "|       115|    1.68|     1| 49|            134|       1|\n",
      "|       201|    1.75|     1| 84|            142|       1|\n",
      "|       136|    1.61|     1| 38|         502414|      -1|\n",
      "|       175|    1.66|     1| 26|         113658|      -1|\n",
      "|       198|    1.81|     0| 61|         112006|      -1|\n",
      "|       217|    1.87|     0| 99|             32|       1|\n",
      "+----------+--------+------+---+---------------+--------+\n",
      "\n",
      "X_test shape: (20, 3)\n",
      "y_test shape: (20, 1)\n",
      "   gender  age  dna_mutations_n\n",
      "0       1   82           140136\n",
      "1       1   97           628871\n",
      "2       0   85           227274\n",
      "3       0   97           387437\n",
      "4       0   47           266538\n",
      "   is_cylon\n",
      "0        -1\n",
      "1        -1\n",
      "2        -1\n",
      "3        -1\n",
      "4        -1\n"
     ]
    }
   ],
   "source": [
    "query3 = f\"\"\"\n",
    "    SELECT \n",
    "        weight_lbs, \n",
    "        height_m,\n",
    "        CASE \n",
    "            WHEN gender = 'M' THEN 0 \n",
    "            WHEN gender = 'F' THEN 1 \n",
    "        END AS gender,\n",
    "        YEAR(DATE('{current_date}')) - YEAR(dob) - \n",
    "            (CASE \n",
    "                WHEN MONTH(DATE('{current_date}')) < MONTH(dob) \n",
    "                        OR (MONTH(DATE('{current_date}')) = MONTH(dob) AND DAY(DATE('{current_date}')) < DAY(dob)) \n",
    "                THEN 1 ELSE 0 \n",
    "                END) AS age,\n",
    "            dna_mutations_n,    \n",
    "        is_cylon\n",
    "           \n",
    "    FROM bsg_people_generated \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bsg_people_generated = spark.read.csv(dir + \"/data/bsg_people_data.csv\", header=True, inferSchema=True) \\\n",
    "    .withColumnRenamed(\"id\", \"person_id\")\n",
    "\n",
    "bsg_people_generated.createOrReplaceTempView(\"bsg_people_generated\")\n",
    "bsg_people_generated = spark.sql(query3)\n",
    "bsg_people_generated.show()\n",
    "\n",
    "df_pandas_test = bsg_people_generated.toPandas()\n",
    "\n",
    "# features = ['weight_lbs', 'height_m', 'gender', 'age', 'dna_mutations_n']\n",
    "X_test = df_pandas_test[features]\n",
    "y_test = df_pandas_test[['is_cylon']]\n",
    "\n",
    "X_test.to_csv(\"./data/X_test.csv\", header=False, index=False)  # No header, no index\n",
    "y_test.to_csv(\"./data/y_test.csv\", header=False, index=False)\n",
    "\n",
    "# X_test.to_csv(\"./data/X_train.csv\", header=False, index=False)  # No header, no index\n",
    "# y_test.to_csv(\"./data/y_train.csv\", header=False, index=False)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(X_test.head())  # Preview features\n",
    "print(y_test.head())  # Preview target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n",
      "(20, 1)\n",
      "(20, 3)\n",
      "(20, 1)\n",
      "\n",
      "[[-1.          0.14606742  0.62737798]\n",
      " [-1.         -0.52808989  0.40498065]\n",
      " [ 1.          0.57303371  0.29961418]\n",
      " [-1.         -0.59550562 -0.3483731 ]\n",
      " [-1.         -0.59550562 -0.08230035]\n",
      " [ 1.         -0.84269663 -0.99817547]\n",
      " [-1.          0.86516854 -0.70790886]\n",
      " [ 1.         -0.50561798 -0.21684354]\n",
      " [-1.         -0.30337079 -0.17517195]\n",
      " [ 1.         -0.7752809  -0.99832332]\n",
      " [-1.         -0.28089888 -0.75231408]\n",
      " [ 1.          0.41573034 -0.99982069]\n",
      " [ 1.         -0.61797753 -0.9994841 ]\n",
      " [-1.         -0.95505618 -0.99898707]\n",
      " [-1.          0.05617978  0.80781433]\n",
      " [ 1.         -0.23595506  0.81799079]\n",
      " [-1.          0.23595506 -0.99959105]\n",
      " [-1.          0.07865169 -0.93983777]\n",
      " [ 1.         -0.91011236 -0.99995596]\n",
      " [ 1.         -0.3258427  -0.9999245 ]]\n"
     ]
    }
   ],
   "source": [
    "# READ in data\n",
    "# df_X_train = pd.read_csv('data/X_train.csv', header=None)\n",
    "# df_y_train = pd.read_csv('data/y_train.csv', header=None)\n",
    "\n",
    "df_X_test = pd.read_csv('data/X_test.csv', header=None)\n",
    "df_y_test = pd.read_csv('data/y_test.csv', header=None)\n",
    "\n",
    "# save in numpy arrays\n",
    "X_train = df_X_train.to_numpy()\n",
    "y_train = df_y_train.to_numpy()\n",
    "X_test = df_X_test.to_numpy()\n",
    "y_test = df_y_test.to_numpy()\n",
    "\n",
    "# get training set size\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# normalize all features to [0,1] or [-1,1]\n",
    "X_all = MyUtils.normalize_neg1_pos1(np.concatenate((X_train, X_test), axis=0))\n",
    "\n",
    "\n",
    "X_train = X_all[:n_train]\n",
    "X_test = X_all[n_train:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print()\n",
    "print(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
