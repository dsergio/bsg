{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/08 22:46:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/08 22:46:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"appName\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ho-yu/bsg\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "\n",
    "import subprocess\n",
    "import yaml\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory set to: /home/ho-yu/bsg/notebooks\n",
      "dir: /home/ho-yu/bsg\n",
      "Current working directory set to: /home/ho-yu/bsg\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory set to:\", os.getcwd())\n",
    "\n",
    "# Read the config.yaml file\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "if os.path.exists('../config.yaml'):\n",
    "    with open('../config.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "dir = config['fileio']['working_directory2']\n",
    "\n",
    "print(\"dir: \" + dir)\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir(dir)\n",
    "print(\"Current working directory set to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+----------+---------+--------------+---------+-----------+---+-----------+-------------------+----------------+----------------+\n",
      "|person_id|first_name|last_name|salutation|call_sign|home_colony_id|colony_id|colony_name| id|action_name|   action_timestamp|source_person_id|target_person_id|\n",
      "+---------+----------+---------+----------+---------+--------------+---------+-----------+---+-----------+-------------------+----------------+----------------+\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica| 85|    forgive|2025-02-08 22:46:29|               1|               5|\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica| 77|     betray|2025-02-08 22:46:29|               1|               7|\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica| 75|       save|2025-02-08 22:46:29|               1|               9|\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica| 64|       help|2025-02-08 22:46:29|               1|               6|\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica| 47|       help|2025-02-08 22:46:29|               1|               4|\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica| 31|       save|2025-02-08 22:46:29|               1|               7|\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica| 12|       help|2025-02-08 22:46:29|               1|               5|\n",
      "|        1|       Lee|    Adama|       Sir|   Apollo|             4|        4|    Caprica|  2|      fight|2025-02-08 22:46:29|               1|               5|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica| 99|       save|2025-02-08 22:46:29|               2|               3|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica| 89|    forgive|2025-02-08 22:46:29|               2|               3|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica| 53|      fight|2025-02-08 22:46:29|               2|              10|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica| 42|     betray|2025-02-08 22:46:29|               2|               1|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica| 35|     betray|2025-02-08 22:46:29|               2|               9|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica| 18|     betray|2025-02-08 22:46:29|               2|               1|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica| 14|       help|2025-02-08 22:46:29|               2|               1|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica|  9|     betray|2025-02-08 22:46:29|               2|               9|\n",
      "|        2|   William|    Adama|       Sir|   Husker|             4|        4|    Caprica|  5|    forgive|2025-02-08 22:46:29|               2|               7|\n",
      "|        3|      Kara|   Thrace|       Sir| Starbuck|             4|        4|    Caprica| 80|      fight|2025-02-08 22:46:29|               3|               6|\n",
      "|        3|      Kara|   Thrace|       Sir| Starbuck|             4|        4|    Caprica| 73|    forgive|2025-02-08 22:46:29|               3|               6|\n",
      "|        3|      Kara|   Thrace|       Sir| Starbuck|             4|        4|    Caprica| 68|      fight|2025-02-08 22:46:29|               3|               6|\n",
      "+---------+----------+---------+----------+---------+--------------+---------+-----------+---+-----------+-------------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+-----------+\n",
      "|colony_name|personCount|\n",
      "+-----------+-----------+\n",
      "|    Aerilon|          1|\n",
      "|      Earth|          1|\n",
      "|    Caprica|          4|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bsg_people = spark.read.csv(dir + \"/csv/people.csv\", header=True, inferSchema=True) \\\n",
    "    .withColumnRenamed(\"id\", \"person_id\")\n",
    "\n",
    "bsg_colonies = spark.read.csv(dir + \"/csv/colonies.csv\", header=True) \\\n",
    "    .withColumnRenamed(\"id\", \"colony_id\") \\\n",
    "    .withColumnRenamed(\"name\", \"colony_name\")\n",
    "\n",
    "bsg_actions = spark.read.csv(dir + \"/csv/person_actions.csv\", header=True)\n",
    "\n",
    "bsg_employees = spark.read.csv(dir + \"/csv/employees.csv\", header=True) \\\n",
    "    .withColumnRenamed(\"id\", \"employee_id\") \\\n",
    "    .withColumnRenamed(\"person_id\", \"employee_person_id\")\n",
    "\n",
    "bsg_empoyers = spark.read.csv(dir + \"/csv/employers.csv\", header=True) \\\n",
    "    .withColumnRenamed(\"id\", \"employer_id\") \\\n",
    "    .withColumnRenamed(\"name\", \"employer_name\")\n",
    "\n",
    "bsg_departments = spark.read.csv(dir + \"/csv/departments.csv\", header=True) \\\n",
    "    .withColumnRenamed(\"id\", \"department_id\") \\\n",
    "    .withColumnRenamed(\"name\", \"department_name\")\n",
    "\n",
    "bsg_data = bsg_people \\\n",
    "    .join(bsg_colonies, bsg_people.home_colony_id == bsg_colonies.colony_id) \\\n",
    "    .join(bsg_actions, bsg_people.person_id == bsg_actions.source_person_id)\n",
    "\n",
    "bsg_data.show()\n",
    "bsg_data.createOrReplaceTempView(\"bsg_data\")\n",
    "bsg_data_count = spark.sql(\"SELECT colony_name, COUNT(DISTINCT(person_id)) personCount FROM bsg_data GROUP BY colony_name\")\n",
    "\n",
    "bsg_data_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------+-----------+\n",
      "|first_name|last_name|     department_name|  salary|colony_name|\n",
      "+----------+---------+--------------------+--------+-----------+\n",
      "|       Lee|    Adama| Tactical Operations|120000.0|    Caprica|\n",
      "|   William|    Adama| Tactical Operations|150000.0|    Caprica|\n",
      "|      Kara|   Thrace|   Flight Operations| 90000.0|    Caprica|\n",
      "|     Gaius|   Baltar|Artificial Intell...|100000.0|    Aerilon|\n",
      "|     Laura|   Roslin|    Executive Branch|200000.0|    Caprica|\n",
      "|      Saul|     Tigh| Tactical Operations|110000.0|      Earth|\n",
      "|     Billy|  Keikeya|    Executive Branch| 85000.0|      Picon|\n",
      "|     Galen|    Tyrol|         Engineering| 95000.0|      Earth|\n",
      "| Anastasia|   Dualla| Tactical Operations| 87000.0| Sagittaron|\n",
      "|      Karl|  Agathon|   Flight Operations| 92000.0|    Caprica|\n",
      "| Samuel T.|   Anders|   Military Strategy|102000.0|      Earth|\n",
      "+----------+---------+--------------------+--------+-----------+\n",
      "\n",
      "+--------------------+----------+\n",
      "|     department_name|avg_salary|\n",
      "+--------------------+----------+\n",
      "|    Executive Branch|  142500.0|\n",
      "| Tactical Operations|  116750.0|\n",
      "|   Military Strategy|  102000.0|\n",
      "|Artificial Intell...|  100000.0|\n",
      "|         Engineering|   95000.0|\n",
      "|   Flight Operations|   91000.0|\n",
      "+--------------------+----------+\n",
      "\n",
      "+----------+---------+--------+--------------------+--------------------+-----------+\n",
      "|first_name|last_name|  salary|            position|     department_name|colony_name|\n",
      "+----------+---------+--------+--------------------+--------------------+-----------+\n",
      "|       Lee|    Adama|120000.0|           Commander| Tactical Operations|    Caprica|\n",
      "|   William|    Adama|150000.0|       Fleet Admiral| Tactical Operations|    Caprica|\n",
      "|      Kara|   Thrace| 90000.0|               Pilot|   Flight Operations|    Caprica|\n",
      "|     Gaius|   Baltar|100000.0|  Research Scientist|Artificial Intell...|    Aerilon|\n",
      "|     Laura|   Roslin|200000.0|           President|    Executive Branch|    Caprica|\n",
      "|      Saul|     Tigh|110000.0|   Executive Officer| Tactical Operations|      Earth|\n",
      "| Samuel T.|   Anders|102000.0|   Resistance Leader|   Military Strategy|      Earth|\n",
      "| Anastasia|   Dualla| 87000.0|Communications Of...| Tactical Operations| Sagittaron|\n",
      "|     Galen|    Tyrol| 95000.0|      Chief Engineer|         Engineering|      Earth|\n",
      "|      Karl|  Agathon| 92000.0|               Pilot|   Flight Operations|    Caprica|\n",
      "|     Billy|  Keikeya| 85000.0|      Chief of Staff|    Executive Branch|      Picon|\n",
      "+----------+---------+--------+--------------------+--------------------+-----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "all_employees = bsg_employees \\\n",
    "    .join(bsg_people, bsg_employees.employee_person_id == bsg_people.person_id) \\\n",
    "    .join(bsg_departments, bsg_employees.dept_id == bsg_departments.department_id) \\\n",
    "    .join(bsg_colonies, bsg_people.home_colony_id == bsg_colonies.colony_id)\n",
    "\n",
    "all_employees.select([\"first_name\", \"last_name\", \"department_name\", \"salary\", \"colony_name\"]).show()\n",
    "\n",
    "# average salary per department\n",
    "all_employees.select([\"department_name\", \"salary\"]) \\\n",
    "    .groupBy(\"department_name\") \\\n",
    "    .agg(avg(\"salary\").alias(\"avg_salary\")) \\\n",
    "    .sort(\"avg_salary\", ascending=False) \\\n",
    "    .show()\n",
    "\n",
    "df_cols = [\"first_name\", \"last_name\", \"salary\", \"position\", \"department_name\", \"colony_name\"]\n",
    "all_employees_df = all_employees.select(df_cols).toDF(*df_cols)\n",
    "\n",
    "print(all_employees_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Picon', 85000.0),\n",
       " ('Sagittaron', 87000.0),\n",
       " ('Aerilon', 100000.0),\n",
       " ('Earth', 102333.33333333333),\n",
       " ('Caprica', 130400.0)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_salary_mapper(row):\n",
    "    # print(row)\n",
    "    return (row.colony_name, (row.salary, 1))\n",
    "\n",
    "\n",
    "all_employees_df.rdd \\\n",
    "    .map(lambda s: avg_salary_mapper(s)) \\\n",
    "    .reduceByKey(lambda a, b: (float(a[0]) + float(b[0]), float(a[1]) + float(b[1]))) \\\n",
    "    .mapValues(lambda s: float(s[0]) / float(s[1])) \\\n",
    "    .sortBy(lambda s: s[1], ascending=True) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Samuel T. Anders',\n",
       "  '102000.0',\n",
       "  'Resistance Leader',\n",
       "  'Military Strategy',\n",
       "  'Earth'),\n",
       " ('Saul Tigh',\n",
       "  '110000.0',\n",
       "  'Executive Officer',\n",
       "  'Tactical Operations',\n",
       "  'Earth'),\n",
       " ('Lee Adama', '120000.0', 'Commander', 'Tactical Operations', 'Caprica'),\n",
       " ('William Adama',\n",
       "  '150000.0',\n",
       "  'Fleet Admiral',\n",
       "  'Tactical Operations',\n",
       "  'Caprica'),\n",
       " ('Laura Roslin', '200000.0', 'President', 'Executive Branch', 'Caprica')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_employees_df.rdd \\\n",
    "    .map(lambda s: (s.first_name + \" \" + s.last_name, s.salary, s.position, s.department_name, s.colony_name)) \\\n",
    "    .filter(lambda s: s[4] == \"Caprica\") \\\n",
    "    .sortBy(lambda s: s[1], ascending=True) \\\n",
    "    .collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
